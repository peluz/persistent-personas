{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e1c15d-fed4-42c2-9eee-747fdb330bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score, mean_absolute_error\n",
    "from transformers import AutoTokenizer\n",
    "from data.loader import load_data\n",
    "import glob\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "from utils.seeds import initialize_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10b12d6-1ac0-429f-b14a-75a219a930c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns_ab = {\n",
    "    \"Selene-1-Mini-Llama-3.1-8B\": {\n",
    "        \"reasoning\":re.compile(r\"\\*\\*Reasoning:\\*\\*(.*?)(\\*\\*Result:\\*\\*|$)\", re.DOTALL),\n",
    "        \"score\": re.compile(r\"\\*\\*Result:\\*\\*\\s+(a|b)\",re.IGNORECASE)\n",
    "    },\n",
    "    \"Flow-Judge-v0.1\": {\n",
    "        \"reasoning\":re.compile(r\"<feedback>(.*?)(</feedback>)|(<score>)\", re.IGNORECASE | re.DOTALL),\n",
    "        \"score\": re.compile(r\"<score>\\n*(\\d+)\\n*</score>\", re.IGNORECASE)\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bb058b-573d-42e4-9534-505968b89b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = {\n",
    "    \"Selene-1-Mini-Llama-3.1-8B\": {\n",
    "        \"reasoning\":re.compile(r\"\\*\\*Reasoning:\\*\\*(.*?)(\\*\\*Result:\\*\\*|$)\", re.DOTALL),\n",
    "        \"score\": re.compile(r\"\\*\\*Result:\\*\\*\\s+(\\d+)\",re.IGNORECASE)\n",
    "    },\n",
    "    \"Flow-Judge-v0.1\": {\n",
    "        \"reasoning\":re.compile(r\"<feedback>(.*?)(</feedback>)|(<score>)\", re.IGNORECASE | re.DOTALL),\n",
    "        \"score\": re.compile(r\"<score>\\n*(\\d+)\\n*</score>\", re.IGNORECASE)\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9f02f9-4433-4e75-9e09-2dfe93dc8027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_within_one(rater1, rater2, gap=1):\n",
    "    \"\"\"\n",
    "    Compute percentage of cases where the absolute difference \n",
    "    between two raters' scores is ≤ 1.\n",
    "\n",
    "    Parameters:\n",
    "        rater1 (list or array): Ratings from annotator 1.\n",
    "        rater2 (list or array): Ratings from annotator 2.\n",
    "\n",
    "    Returns:\n",
    "        float: Percentage of agreement within ±1.\n",
    "    \"\"\"\n",
    "    rater1 = np.array(rater1)\n",
    "    rater2 = np.array(rater2)\n",
    "    \n",
    "    # Mask out missing values if using np.nan\n",
    "    mask = ~np.isnan(rater1) & ~np.isnan(rater2)\n",
    "    r1 = rater1[mask]\n",
    "    r2 = rater2[mask]\n",
    "\n",
    "    within_one = np.abs(r1 - r2) <= gap\n",
    "    return np.mean(within_one) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a332fa22-93c5-4861-b073-66e6d19e7c47",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc868b3e-fe65-4592-a141-8e4fcd117ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = glob.glob(f\"./metrics/*/*/*/instructions*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef9781c-f60b-46df-954c-b8b4891b7b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = []\n",
    "role = []\n",
    "response = []\n",
    "metric = []\n",
    "model = []\n",
    "for m in metrics:\n",
    "    judge.append(m.split(\"/\")[3])\n",
    "    metric.append(m.split(\"/\")[2])\n",
    "    model.append(m.split(\"/\")[4])\n",
    "    role.append(Path(m).name)\n",
    "    response.append(pd.read_csv(m)[metric[-1]].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d9fbcf-6871-4df8-a008-44b440720923",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"judge\": judge, \"role\": role, \"response\": response, \"metric\": metric, \"model\": model})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c4f1dd-cf2b-4607-a65e-04ef77456b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"reasoning\"] = df.apply(lambda x: [patterns[x[\"judge\"]][\"reasoning\"].search(y).group(1) for y in x[\"response\"]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba70a9c-f90b-494d-bbe5-d9cef5d9f4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score\"] = df.apply(lambda x: [int(patterns[x[\"judge\"]][\"score\"].search(y).group(1)) if patterns[x[\"judge\"]][\"score\"].search(y) is not None else int(re.search(r\"score of (\\d)\", y).group(1))  for y in x[\"response\"]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180637f3-a8a4-45b1-914c-827caa2cfc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93168158-76fa-406c-abfe-685e61f45d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "judges = list(np.unique(df.judge))\n",
    "roles = list(np.unique(df.role))\n",
    "metrics = list(np.unique(df.metric))\n",
    "models = list(np.unique(df.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9826414b-8ff1-409c-879b-3a9b5b67ca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index([\"metric\", \"model\", \"judge\", \"role\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038e81aa-01a9-41ea-aa31-ca700c513e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "judge1_scores = []\n",
    "all_metrics = []\n",
    "all_roles = []\n",
    "all_models = []\n",
    "idxs = []\n",
    "for metric in metrics:\n",
    "    for role in roles:\n",
    "        for model in models:\n",
    "            judge1 = df.loc[metric,model, judges[0], role].score\n",
    "            judge1_scores.extend(judge1)\n",
    "            all_models.extend([model]*len(judge1))\n",
    "            all_metrics.extend([metric]*len(judge1))\n",
    "            all_roles.extend([role]*len(judge1))\n",
    "            idxs.extend(list(range(len(judge1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080a42b3-e91d-4aa8-80c4-bd61709b9676",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.DataFrame({\"model\": all_models, \"metric\": all_metrics, \"role\": all_roles, \"idx\": idxs, judges[0]: judge1_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373cd792-2010-4627-9d8b-8b66b8f05c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25baa39-6134-496c-bbfe-935d86b123bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.to_csv(\"results/instructions_ratings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcebfc3-d740-4d82-9add-0f68eeff037b",
   "metadata": {},
   "source": [
    "## Interview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e5c72f-385c-474e-aade-58d7a677fd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = glob.glob(f\"./metrics/*/*/*/interview*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f28a884-e695-4f36-9020-54958c53a920",
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = []\n",
    "role = []\n",
    "response = []\n",
    "metric = []\n",
    "model = []\n",
    "for m in metrics:\n",
    "    if \"Selene\" not in m.split(\"/\")[3]:\n",
    "        continue\n",
    "    judge.append(m.split(\"/\")[3])\n",
    "    metric.append(m.split(\"/\")[2])\n",
    "    model.append(m.split(\"/\")[4])\n",
    "    role.append(Path(m).name)\n",
    "    response.append(pd.read_csv(m)[metric[-1]].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15eb15d-17d7-4dc7-9534-bff6fa693a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"judge\": judge, \"role\": role, \"response\": response, \"metric\": metric, \"model\": model})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6039cbb-bca1-4394-968e-b083c75ec9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"reasoning\"] = df.apply(lambda x: [patterns[x[\"judge\"]][\"reasoning\"].search(y).group(1) for y in x[\"response\"]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38893839-08c4-4b55-9492-3fb59702e840",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score\"] = df.apply(lambda x: [int(patterns[x[\"judge\"]][\"score\"].search(y).group(1)) if patterns[x[\"judge\"]][\"score\"].search(y) is not None else int(re.search(r\"score of (\\d)\", y).group(1))  for y in x[\"response\"]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a8a2b9-6ecb-4ef6-9ef3-e82ab57cb289",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfe5f5f-36d9-4a1d-b9bc-5dca13757710",
   "metadata": {},
   "outputs": [],
   "source": [
    "judges = list(np.unique(df.judge))\n",
    "roles = list(np.unique(df.role))\n",
    "metrics = list(np.unique(df.metric))\n",
    "models = list(np.unique(df.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8111d516-42e0-4e61-8a4c-20388fad8d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index([\"metric\", \"model\", \"judge\", \"role\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b19eaa7-63cf-49c7-a703-87fd35f1c5e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "judge1_scores = []\n",
    "all_metrics = []\n",
    "all_roles = []\n",
    "all_models = []\n",
    "idxs = []\n",
    "for metric in metrics:\n",
    "    for role in roles:\n",
    "        for model in models:\n",
    "            judge1 = df.loc[metric,model, judges[0], role].score\n",
    "            judge1_scores.extend(judge1)\n",
    "            all_models.extend([model]*len(judge1))\n",
    "            all_metrics.extend([metric]*len(judge1))\n",
    "            all_roles.extend([role]*len(judge1))\n",
    "            idxs.extend(list(range(len(judge1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0639af-f2a7-4220-9a88-4c640e7ba8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.DataFrame({\"model\": all_models, \"metric\": all_metrics, \"role\": all_roles, \"idx\": idxs, judges[0]: judge1_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7afec5-7b42-41ef-87f3-1e1c5b446710",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ff2452-3265-4e4d-9126-88c1a8e3adf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.to_csv(\"results/interview_ratings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf0c604-a135-40ce-8ece-88080c415833",
   "metadata": {},
   "source": [
    "## bfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7755e126-2fbd-42b4-92f3-4b96814c3d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = glob.glob(f\"./metrics/bfi/*/*/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ef7a0f-12c7-4f45-bb6c-3f247ffe8da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = []\n",
    "response = []\n",
    "model = []\n",
    "judge = []\n",
    "for m in metrics:\n",
    "    role.append(Path(m).name)\n",
    "    judge.append(m.split(\"/\")[-3])\n",
    "    model.append(m.split(\"/\")[-2])\n",
    "    response.append(pd.read_csv(m)[\"bfi\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e371c61-61a8-4df5-ab96-2ecc6cf547f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"model\": model, \"judge\": judge, \"role\": role, \"response\": response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e7024a-b8e9-4e3c-965b-bd615157febb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"reasoning\"] = df.apply(lambda x: [patterns[x[\"judge\"]][\"reasoning\"].search(y).group(1) for y in x[\"response\"]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4883df-4e7d-4739-abf8-14c06a927150",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score\"] = df.apply(lambda x: [int(patterns[x[\"judge\"]][\"score\"].search(y).group(1)) for y in x[\"response\"]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febe95c2-da80-467a-97fe-8aea2a6eaadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(df.judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7e53fe-9a64-4726-8c5f-a6e57f7e735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "all_roles = []\n",
    "all_models = []\n",
    "idxs = []\n",
    "for _, row in df.iterrows():\n",
    "    if \"Selene\" not in row.judge: continue\n",
    "    scores = row.score\n",
    "    role = row.role\n",
    "    model = row.model\n",
    "    all_scores.extend(scores)\n",
    "    all_roles.extend([role]*len(scores))\n",
    "    all_models.extend([model]*len(scores))\n",
    "    idxs.extend(list(range(len(scores))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d78f805-6c6d-4244-9567-8ee3e75b939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.DataFrame({\"model\": all_models, \"role\": all_roles, \"idx\": idxs, \"rating\": all_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324419f2-faff-4e51-9167-9c195321849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.to_csv(\"results/bfi_ratings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60282880-59a9-444b-b4ca-a05f9078746f",
   "metadata": {},
   "source": [
    "## Instruction role specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b2a86e-dd05-42c1-9dfb-b1fc550a0177",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = glob.glob(f\"./metrics/instruction_role_specific/*/*/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd51a2b-62f5-4152-bf33-a50756fa284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = []\n",
    "response = []\n",
    "model = []\n",
    "judge = []\n",
    "for m in metrics:\n",
    "    role.append(Path(m).name)\n",
    "    judge.append(m.split(\"/\")[-3])\n",
    "    model.append(m.split(\"/\")[-2])\n",
    "    response.append(pd.read_csv(m)[\"instruction_role_specific\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e341dcf-81a6-4982-ba34-3e7b931a5d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"model\": model, \"judge\": judge, \"role\": role, \"response\": response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469a0b15-96bd-4a95-8b00-6429798016b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"reasoning\"] = df.apply(lambda x: [patterns_ab[x[\"judge\"]][\"reasoning\"].search(y).group(1) for y in x[\"response\"]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d49ed8f-0e4e-42ee-96b7-40f58414015e",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91625c5e-59c6-43df-a33b-1a2696e09a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score\"] = df.apply(lambda x: [patterns_ab[x[\"judge\"]][\"score\"].search(y).group(1) if patterns_ab[x[\"judge\"]][\"score\"].search(y) is not None else np.random.choice([\"A\", \"B\"]) for y in x[\"response\"]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b909d3-e1f7-4d7e-b68d-8ccbad2301ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "all_roles = []\n",
    "all_models = []\n",
    "idxs = []\n",
    "reasonings = []\n",
    "for _, row in df.iterrows():\n",
    "    scores = row.score\n",
    "    role = row.role\n",
    "    model = row.model\n",
    "    all_scores.extend(scores)\n",
    "    all_roles.extend([role]*len(scores))\n",
    "    all_models.extend([model]*len(scores))\n",
    "    reasonings.extend(row.reasoning)\n",
    "    idxs.extend(list(range(len(scores))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2681ff-90ec-40f3-ae12-49ad05091e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.DataFrame({\"model\": all_models, \"role\": all_roles, \"idx\": idxs, \"rating\": all_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd32446-7132-47aa-ae46-58f319e7b33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e2ad2f-2a0c-4e5a-a169-001bf5d97166",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings[ratings.idx%2==0].rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8cc0c2-b131-4532-b095-94ddba8b105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings[ratings.idx%2!=0].rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1487710-747c-4ac0-873a-c2b7ab814c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.to_csv(\"results/instruction_role_specific_ratings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e909f32-001a-4415-a535-33ec6c18d300",
   "metadata": {},
   "source": [
    "## instruction_general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d784f81-9182-4167-818b-afaebdb36ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = glob.glob(f\"./metrics/instruction_general/*/*/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d642dd38-a164-41c5-8b56-3b4962739422",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = []\n",
    "response = []\n",
    "model = []\n",
    "judge = []\n",
    "for m in metrics:\n",
    "    role.append(Path(m).name)\n",
    "    judge.append(m.split(\"/\")[-3])\n",
    "    model.append(m.split(\"/\")[-2])\n",
    "    response.append(pd.read_csv(m)[\"instruction_general\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b979705c-f14f-40eb-8643-51cfcd2f4002",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"model\": model, \"judge\": judge, \"role\": role, \"response\": response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b37978-081f-42ff-8641-342fecdb45b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dd3c48-8f71-4e3f-9878-67c81dcb67a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"reasoning\"] = df.apply(lambda x: [patterns_ab[x[\"judge\"]][\"reasoning\"].search(y).group(1) if patterns_ab[x[\"judge\"]][\"reasoning\"].search(y) is not None else print(y) for y in x[\"response\"]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4827319-a963-49c9-874b-9fe331ae1c92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"score\"] = df.apply(lambda x: [patterns_ab[x[\"judge\"]][\"score\"].search(y).group(1) if patterns_ab[x[\"judge\"]][\"score\"].search(y) is not None else random.choice([\"A\", \"B\"]) for y in x[\"response\"]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89870005-a2e8-45b3-b405-c67866441234",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "all_roles = []\n",
    "all_models = []\n",
    "idxs = []\n",
    "reasonings = []\n",
    "for _, row in df.iterrows():\n",
    "    scores = row.score\n",
    "    role = row.role\n",
    "    model = row.model\n",
    "    all_scores.extend(scores)\n",
    "    all_roles.extend([role]*len(scores))\n",
    "    all_models.extend([model]*len(scores))\n",
    "    reasonings.extend(row.reasoning)\n",
    "    idxs.extend(list(range(len(scores))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5334f945-7a92-4f2f-95b1-c9e38c007b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.DataFrame({\"model\": all_models, \"role\": all_roles, \"idx\": idxs, \"rating\": all_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bb8057-2cbc-4012-8be9-fdc7760e1db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f28d3e-c3b8-4bb7-8be6-3af4ff100124",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings[ratings.idx%2==0].rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caad937d-0dc1-4e9b-824f-fb10542708cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings[ratings.idx%2!=0].rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c57fb85-18d4-4e5d-8108-e77d9ee7b807",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.to_csv(\"results/instruction_general_ratings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c26855-8ec5-4d08-894a-b19d8240e17b",
   "metadata": {},
   "source": [
    "## xstest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b54abd7-80f6-4bde-b1ba-12ecea5e0ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = {\n",
    "    \"Selene-1-Mini-Llama-3.1-8B\": {\n",
    "        \"reasoning\":re.compile(r\"\\*\\*Reasoning:\\*\\*(.*?)(\\*\\*Result:\\*\\*|$)\", re.DOTALL),\n",
    "        \"score\": re.compile(r\"\\*\\*Result:\\*\\*\\s+(yes|no)\",re.IGNORECASE)\n",
    "    },\n",
    "    \"Flow-Judge-v0.1\": {\n",
    "        \"reasoning\":re.compile(r\"<feedback>(.*?)(</feedback>)|(<score>)\", re.IGNORECASE | re.DOTALL),\n",
    "        \"score\": re.compile(r\"<score>\\n*(\\d+)\\n*</score>\", re.IGNORECASE)\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7ac113-40b8-4f28-89c1-ffe44eb6caa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = glob.glob(f\"./metrics/xstest/*/*/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc93834-9920-41d8-a85c-132943b38aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = []\n",
    "response = []\n",
    "model = []\n",
    "judge = []\n",
    "for m in metrics:\n",
    "    role.append(Path(m).name)\n",
    "    judge.append(m.split(\"/\")[-3])\n",
    "    model.append(m.split(\"/\")[-2])\n",
    "    response.append(pd.read_csv(m)[\"xstest\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef495155-1dc7-489c-a907-e06e29e59a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"model\": model, \"judge\": judge, \"role\": role, \"response\": response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec9be21-f684-43c0-910b-daa24f612fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"reasoning\"] = df.apply(lambda x: [patterns_ab[x[\"judge\"]][\"reasoning\"].search(y).group(1) if patterns[x[\"judge\"]][\"reasoning\"].search(y) is not None else print(y) for y in x[\"response\"]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b62e053-cd14-4778-a375-b09e56723249",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score\"] = df.apply(lambda x: [patterns[x[\"judge\"]][\"score\"].search(y).group(1) if patterns[x[\"judge\"]][\"score\"].search(y) is not None else print(y) for y in x[\"response\"]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeba018-0f1f-4e03-a324-41dfbbc1580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "all_roles = []\n",
    "all_models = []\n",
    "idxs = []\n",
    "reasonings = []\n",
    "for _, row in df.iterrows():\n",
    "    scores = row.score\n",
    "    role = row.role\n",
    "    model = row.model\n",
    "    all_scores.extend(scores)\n",
    "    all_roles.extend([role]*len(scores))\n",
    "    all_models.extend([model]*len(scores))\n",
    "    reasonings.extend(row.reasoning)\n",
    "    idxs.extend(list(range(len(scores))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d26c96-2c1c-4bb9-8fdd-e756976d2a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.DataFrame({\"model\": all_models, \"role\": all_roles, \"idx\": idxs, \"rating\": all_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8173b754-dc67-40d3-abbb-a6e303f3a017",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.to_csv(\"results/xstest_ratings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4f233a-d46f-4686-9a54-ec69216328d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "persistent-personas",
   "language": "python",
   "name": "persistent-personas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
