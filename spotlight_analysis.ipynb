{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc6c6af-62c4-48b3-bad7-5f7420ea4e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import re\n",
    "import pickle\n",
    "import spacy\n",
    "import glob\n",
    "import random\n",
    "from pypremise import Premise, data_loaders\n",
    "from data.constants import DATASETS\n",
    "import matplotlib.font_manager as fm\n",
    "import statsmodels.formula.api as smf\n",
    "from contextlib import redirect_stdout\n",
    "from data.constants import DATASETS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import os\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9952e6-798f-4751-b87c-f3491bc04a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.fontManager.addfont(\"/usr/share/fonts/truetype/cmu/cmunrm.ttf\")   # regular\n",
    "fm.fontManager.addfont(\"/usr/share/fonts/truetype/cmu/cmunbx.ttf\")   # bold\n",
    "bold_font = fm.FontProperties(fname=\"/usr/share/fonts/truetype/cmu/cmunbx.ttf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84411eb8-22d9-48d3-a1c6-87a6009dff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmu_serif = fm.FontProperties(fname=\"/usr/share/fonts/truetype/cmu/cmunrm.ttf\").get_name()\n",
    "print(\"Font name:\", cmu_serif)  # should be \"CMU Serif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67a9f22-9c95-427f-91a2-b27998073591",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    \"text.usetex\": False,  # Enable LaTeX\n",
    "    \"mathtext.fontset\": \"cm\",  # Use Computer Modern (LaTeX default)\n",
    "    \"font.family\": cmu_serif,\n",
    "    \"font.size\": 16,         # Base font size\n",
    "    \"axes.titlesize\": 18,    # Title font size\n",
    "    \"axes.labelsize\": 16,    # Axis label font size\n",
    "    \"xtick.labelsize\": 14,   # X-axis tick font size\n",
    "    \"ytick.labelsize\": 14,   # Y-axis tick font size\n",
    "    \"legend.fontsize\": 16    # Legend font size\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cd3e21-0626-45a9-8336-9d3f7c64e1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_order = [\n",
    "    \"Llama-3.1-Nemotron-Nano-8B-v1\", \"Llama-3_3-Nemotron-Super-49B-v1\",\n",
    "     \"gemma-3-4b-it\", \"gemma-3-27b-it\",\n",
    "    \"Qwen3-4B-Instruct-2507\", \"Qwen3-30B-A3B-Instruct-2507\",\n",
    "    \"gemini-2.5-flash\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556974cc-fc81-4670-96d8-334c180e554a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_role_no_role_heatmaps(\n",
    "    df,\n",
    "    count_col=\"count_in_role_gen\",\n",
    "    pattern_group_col=\"pattern_group\",\n",
    "    model_col=\"model\",\n",
    "    setting_col=\"setting\",\n",
    "    turn_col=\"turn\",\n",
    "    role_value=1,\n",
    "    no_role_value=0,\n",
    "    normalize=None,    # None | \"row\" | \"global\"\n",
    "    sort_by_role_slope=False,\n",
    "    model_order=None,  # New parameter for custom ordering\n",
    "    figsize=(12, 8),\n",
    "    vmax=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots 2x2 grid of heatmaps: role vs no-role x persona-directed vs goal-oriented.\n",
    "\n",
    "    Color scheme:\n",
    "      - Persona-directed: Orange (role), Grey (no-role)\n",
    "      - Goal-oriented:    Blue    (role), Grey (no-role)\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Step 1. Bin turns to fixed 10 bins (0–9) ---\n",
    "    df = df.copy()\n",
    "    df[\"turn_bin\"] = df[turn_col] // 11    # adjust divisor if spacing changes\n",
    "    df[\"turn_bin\"] = df[\"turn_bin\"].clip(upper=9)\n",
    "\n",
    "    # --- Shorten model names based on the mapping\n",
    "    model_name_map = {\n",
    "        \"Llama-3.1-Nemotron-Nano-8B-v1\": \"Nemotron-8B\",\n",
    "        \"Llama-3_3-Nemotron-Super-49B-v1\": \"Nemotron-49B\",\n",
    "        \"gemma-3-4b-it\": \"Gemma3-4B\",\n",
    "        \"gemma-3-27b-it\": \"Gemma3-27B\",\n",
    "        \"Qwen3-4B-Instruct-2507\": \"Qwen3-4B\",\n",
    "        \"Qwen3-30B-A3B-Instruct-2507\": \"Qwen3-30B\",\n",
    "        \"gemini-2.5-flash\": \"gemini-2.5-flash\"\n",
    "    }\n",
    "    df[model_col] = df[model_col].replace(model_name_map)\n",
    "\n",
    "    # --- Step 2. Aggregate counts ---\n",
    "    agg = (\n",
    "        df.groupby([model_col, setting_col, \"turn_bin\", pattern_group_col], as_index=False)[count_col]\n",
    "        .sum()\n",
    "        .rename(columns={count_col: \"count\"})\n",
    "    )\n",
    "\n",
    "    turns = list(range(10))  # always 10 turns\n",
    "\n",
    "    # --- Determine the final model order based on parameters ---\n",
    "    if sort_by_role_slope:\n",
    "        # If sorting by slope is requested, override the custom model_order\n",
    "        # and sort based on the calculated slopes.\n",
    "        models = sorted(df[model_col].unique())\n",
    "        sub_role_persona = agg[(agg[setting_col] == \"persona-directed\") & (agg[pattern_group_col] == role_value)]\n",
    "        mat_role_persona = sub_role_persona.pivot_table(index=model_col, columns=\"turn_bin\", values=\"count\", aggfunc=\"sum\")\n",
    "        mat_role_persona = mat_role_persona.reindex(index=models, columns=turns, fill_value=0)\n",
    "        \n",
    "        x = np.arange(mat_role_persona.shape[1])\n",
    "        slopes = {}\n",
    "        for idx, row in mat_role_persona.iterrows():\n",
    "            y = row.values.astype(float)\n",
    "            mask = y > 0\n",
    "            if mask.sum() >= 2:\n",
    "                slopes[idx] = np.polyfit(x[mask], y[mask], 1)[0]\n",
    "            else:\n",
    "                slopes[idx] = 0\n",
    "        final_model_order = sorted(models, key=lambda m: slopes[m])\n",
    "        \n",
    "    elif model_order is not None:\n",
    "        # Use the provided custom model_order list\n",
    "        final_model_order = [model_name_map.get(m, m) for m in model_order]\n",
    "    else:\n",
    "        # Default to alphabetical sort of unique models\n",
    "        final_model_order = sorted(df[model_col].unique())\n",
    "\n",
    "    def make_matrix(setting, pg_value):\n",
    "        sub = agg[(agg[setting_col] == setting) & (agg[pattern_group_col] == pg_value)]\n",
    "        mat = sub.pivot_table(index=model_col, columns=\"turn_bin\", values=\"count\", aggfunc=\"sum\")\n",
    "        # Reindex with the final, determined model order\n",
    "        return mat.reindex(index=final_model_order, columns=turns, fill_value=0)\n",
    "\n",
    "    # --- Step 3. Build matrices ---\n",
    "    role_persona = make_matrix(\"persona-directed\", role_value)\n",
    "    no_role_persona = make_matrix(\"persona-directed\", no_role_value)\n",
    "    role_goal = make_matrix(\"goal-oriented\", role_value)\n",
    "    no_role_goal = make_matrix(\"goal-oriented\", no_role_value)\n",
    "\n",
    "    # --- Step 4. Optional: sort by slope (role, persona-directed) ---\n",
    "    # This step is now handled by the logic above, so we can skip it here.\n",
    "    # The dataframes are already created in the desired order.\n",
    "\n",
    "    if normalize == \"row\":\n",
    "        # Combine dataframes to find the maximum per row across both variants\n",
    "        role_combined = pd.concat([role_persona, role_goal], axis=1)\n",
    "        role_maxes = role_combined.max(axis=1).replace(0, np.nan)\n",
    "        no_role_combined = pd.concat([no_role_persona, no_role_goal], axis=1)\n",
    "        no_role_maxes = no_role_combined.max(axis=1).replace(0, np.nan)\n",
    "        \n",
    "        role_persona_n = role_persona.div(role_maxes, axis=0).fillna(0)\n",
    "        role_goal_n = role_goal.div(role_maxes, axis=0).fillna(0)\n",
    "        no_role_persona_n = no_role_persona.div(no_role_maxes, axis=0).fillna(0)\n",
    "        no_role_goal_n = no_role_goal.div(no_role_maxes, axis=0).fillna(0)\n",
    "        \n",
    "        mats = [role_persona_n, no_role_persona_n, role_goal_n, no_role_goal_n]\n",
    "        \n",
    "    elif normalize == \"global\":\n",
    "        gmax = max(m.values.max() for m in [role_persona, no_role_persona, role_goal, no_role_goal])\n",
    "        gmax = gmax if gmax > 0 else 1\n",
    "        mats = [m / gmax for m in [role_persona, no_role_persona, role_goal, no_role_goal]]\n",
    "\n",
    "    else: # normalize is None\n",
    "        mats = [role_persona, no_role_persona, role_goal, no_role_goal]\n",
    "\n",
    "    role_persona_n, no_role_persona_n, role_goal_n, no_role_goal_n = mats\n",
    "\n",
    "    # --- Step 6. Set vmax for consistent colormap scaling ---\n",
    "    if vmax is None:\n",
    "        if normalize in (\"row\", \"global\"):\n",
    "            vmax = 1.0\n",
    "        else:\n",
    "            vmax = np.percentile(np.concatenate([m.values.flatten() for m in mats]), 99)\n",
    "\n",
    "    # --- Step 7. Plot ---\n",
    "    fig, axes = plt.subplots(2, 2, figsize=figsize, sharex=True, sharey=True)\n",
    "\n",
    "    sns.heatmap(role_persona_n, ax=axes[0, 0], cmap=\"viridis\", cbar=True, annot_kws={\"fontsize\":12}, annot=True, vmin=0, vmax=vmax)\n",
    "    axes[0, 0].set_title(\"Role patterns — persona-directed\", fontproperties=bold_font, fontsize=14)\n",
    "\n",
    "    # Use a lighter color palette for the no-role patterns\n",
    "    sns.heatmap(no_role_persona_n, ax=axes[1, 0], cmap=\"viridis\", cbar=True, annot_kws={\"fontsize\":12}, annot=True, vmin=0, vmax=vmax)\n",
    "    axes[1, 0].set_title(\"No-role patterns — persona-directed\", fontproperties=bold_font, fontsize=14)\n",
    "\n",
    "    sns.heatmap(role_goal_n, ax=axes[0, 1], cmap=\"viridis\", cbar=True,annot=True, annot_kws={\"fontsize\":12}, vmin=0, vmax=vmax)\n",
    "    axes[0, 1].set_title(\"Role patterns — goal-oriented\", fontproperties=bold_font, fontsize=14)\n",
    "\n",
    "    # Use a lighter color palette for the no-role patterns\n",
    "    sns.heatmap(no_role_goal_n, ax=axes[1, 1], cmap=\"viridis\", cbar=True, annot=True,annot_kws={\"fontsize\":12}, vmin=0, vmax=vmax)\n",
    "    axes[1, 1].set_title(\"No-role patterns — goal-oriented\", fontproperties=bold_font, fontsize=14)\n",
    "\n",
    "    # Create more meaningful x-axis labels\n",
    "    turn_labels = np.unique(df.turn)\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        #ax.set_xlabel(\"Conversation round\")\n",
    "        ax.set_ylabel(\"\")\n",
    "        ax.set_xticks(np.arange(len(turns)) + 0.5)\n",
    "        ax.set_xticklabels(turn_labels, rotation=0)\n",
    "        # Add horizontal lines to distinguish model families\n",
    "        model_family_breaks = [2, 4, 6]  # Corresponds to Gemma, Nemotron, Qwen\n",
    "        if i % 2 == 0:\n",
    "            sec_y = ax.secondary_yaxis(location='left')\n",
    "            sec_y.set_yticks([2, 4, 6])\n",
    "            sec_y.set_yticklabels([])\n",
    "            sec_y.tick_params(axis='y', length=80, width=1, color='black')\n",
    "        for y_pos in model_family_breaks:\n",
    "            ax.axhline(y_pos, color='black', linestyle='--', linewidth=1,clip_on=False)\n",
    "            \n",
    "    axes[1, 0].set_xlabel(\"Conversation round\")\n",
    "    axes[1, 1].set_xlabel(\"Conversation round\")\n",
    "    axes[0, 0].set_xlabel(\"\")\n",
    "    axes[0, 1].set_xlabel(\"\")\n",
    "\n",
    "    #plt.suptitle(\"Role vs No-role token patterns over conversation rounds\", fontsize=14)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n",
    "\n",
    "    return {\n",
    "        \"role_persona\": role_persona,\n",
    "        \"no_role_persona\": no_role_persona,\n",
    "        \"role_goal\": role_goal,\n",
    "        \"no_role_goal\": no_role_goal,\n",
    "        \"role_persona_normed\": role_persona_n,\n",
    "        \"no_role_persona_normed\": no_role_persona_n,\n",
    "        \"role_goal_normed\": role_goal_n,\n",
    "        \"no_role_goal_normed\": no_role_goal_n,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc36667-9d17-46f6-90c1-b639b4cba25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.read_csv(\"./results/all_pattern_counts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b45a33-e954-454a-b44e-9f485fa7ddfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_role_no_role_heatmaps(\n",
    "    master_df,\n",
    "    normalize=\"row\",          # try: None, \"row\", \"global\"\n",
    "    sort_by_role_slope=False,  # set True if you want strongest decays at top\n",
    "    figsize=(12, 8),\n",
    "    model_order=model_order\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815d10db-9ee0-4d8e-984c-fefbc2f5f4cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agg_df = master_df.groupby([\"model\", \"turn\", \"setting\", \"pattern_group\"]).agg({\"count_in_role_gen\": \"sum\", \"count_in_no_role_gen\": \"sum\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d094958-b279-406f-9f7f-3ecb247f79f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_order = [\n",
    "    \"Llama-3.1-Nemotron-Nano-8B-v1\", \"Llama-3_3-Nemotron-Super-49B-v1\",\n",
    "    \"gemma-3-4b-it\", \"gemma-3-27b-it\",\n",
    "    \"Qwen3-4B-Instruct-2507\", \"Qwen3-30B-A3B-Instruct-2507\",\n",
    "    \"gemini-2.5-flash\"\n",
    "]\n",
    "\n",
    "model_name_map = {\n",
    "    \"Llama-3.1-Nemotron-Nano-8B-v1\": \"Nemotron-8B\",\n",
    "    \"Llama-3_3-Nemotron-Super-49B-v1\": \"Nemotron-49B\",\n",
    "    \"gemma-3-4b-it\": \"Gemma3-4B\",\n",
    "    \"gemma-3-27b-it\": \"Gemma3-27B\",\n",
    "    \"Qwen3-4B-Instruct-2507\": \"Qwen3-4B\",\n",
    "    \"Qwen3-30B-A3B-Instruct-2507\": \"Qwen3-30B\",\n",
    "    \"gemini-2.5-flash\": \"gemini-2.5-flash\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8248e51c-e820-487c-b59e-c0e36ba9c9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = agg_df.copy()\n",
    "\n",
    "model_order = [\n",
    "    \"Llama-3.1-Nemotron-Nano-8B-v1\", \"Llama-3_3-Nemotron-Super-49B-v1\",\n",
    "    \"gemma-3-4b-it\", \"gemma-3-27b-it\",\n",
    "    \"Qwen3-4B-Instruct-2507\", \"Qwen3-30B-A3B-Instruct-2507\",\n",
    "    \"gemini-2.5-flash\"\n",
    "]\n",
    "\n",
    "model_name_map = {\n",
    "    \"Llama-3.1-Nemotron-Nano-8B-v1\": \"Nemotron-8B\",\n",
    "    \"Llama-3_3-Nemotron-Super-49B-v1\": \"Nemotron-49B\",\n",
    "    \"gemma-3-4b-it\": \"Gemma3-4B\",\n",
    "    \"gemma-3-27b-it\": \"Gemma3-27B\",\n",
    "    \"Qwen3-4B-Instruct-2507\": \"Qwen3-4B\",\n",
    "    \"Qwen3-30B-A3B-Instruct-2507\": \"Qwen3-30B\",\n",
    "    \"gemini-2.5-flash\": \"gemini-2.5-flash\"\n",
    "}\n",
    "\n",
    "# Filter and rename models based on user input\n",
    "df_filtered = df[df['model'].isin(model_order)].copy()\n",
    "df_filtered['model'] = df_filtered['model'].map(model_name_map)\n",
    "\n",
    "# Get unique, reordered models from the filtered data\n",
    "unique_models = [model_name_map[m] for m in model_order if m in df['model'].unique()]\n",
    "\n",
    "# Define unique settings\n",
    "settings = df_filtered['setting'].unique()\n",
    "\n",
    "# Define colors for settings\n",
    "colors = {'goal-oriented': 'blue', 'persona-directed': 'orange'}\n",
    "\n",
    "# Create a figure and a set of subplots\n",
    "fig, axs = plt.subplots(nrows=len(unique_models), ncols=len(settings), figsize=(12, 4 * len(unique_models)), sharey=True)\n",
    "\n",
    "# Handle the case where there is only one model to prevent indexing error on axs\n",
    "if len(unique_models) == 1:\n",
    "    axs = axs.reshape(1, 2)\n",
    "\n",
    "# Iterate through models (rows) and settings (columns)\n",
    "for i, model in enumerate(unique_models):\n",
    "    for j, setting in enumerate(settings):\n",
    "        ax = axs[i, j]\n",
    "\n",
    "        # Filter data for the current subplot\n",
    "        df_plot_filtered = df_filtered[(df_filtered['model'] == model) & (df_filtered['setting'] == setting)].copy()\n",
    "\n",
    "        # Normalize 'count_in_role_gen' within this subplot\n",
    "        max_val = df_plot_filtered['count_in_role_gen'].max()\n",
    "        if max_val > 0:\n",
    "            df_plot_filtered['normalized_count'] = df_plot_filtered['count_in_role_gen'] / max_val\n",
    "        else:\n",
    "            df_plot_filtered['normalized_count'] = 0\n",
    "\n",
    "        # Plot for each pattern group using the normalized values\n",
    "        for pattern_group in df_plot_filtered['pattern_group'].unique():\n",
    "            df_pattern = df_plot_filtered[df_plot_filtered['pattern_group'] == pattern_group]\n",
    "            linestyle = '--' if pattern_group == 0 else '-'\n",
    "            label = f'Pattern Group {pattern_group}'\n",
    "            color = colors[setting]\n",
    "\n",
    "            ax.plot(df_pattern['turn'], df_pattern['normalized_count'],\n",
    "                    linestyle=linestyle, color=color, label=label)\n",
    "\n",
    "        # Set labels and title\n",
    "        ax.set_title(f'Model: {model}\\nSetting: {setting}')\n",
    "        ax.set_xlabel('Turn')\n",
    "        ax.set_ylabel('Normalized Count in Role Gen')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "        ax.set_ylim(0, 1.1)\n",
    "\n",
    "# Adjust layout and save the figure\n",
    "plt.tight_layout()\n",
    "#plt.savefig('normalized_model_performance_subplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96a0634-6627-4640-81f4-27047df6e336",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_filtered = master_df.groupby([\"dataset\", \"turn\", \"setting\", \"pattern_group\"]).agg({\"count_in_role_gen\": \"sum\", \"count_in_no_role_gen\": \"sum\"}).reset_index().copy()\n",
    "\n",
    "# Get unique, reordered models from the filtered data\n",
    "unique_models = np.unique(df_filtered.dataset)\n",
    "\n",
    "# Define unique settings\n",
    "settings = df_filtered['setting'].unique()\n",
    "\n",
    "# Define colors for settings\n",
    "colors = {'goal-oriented': 'blue', 'persona-directed': 'orange'}\n",
    "\n",
    "# Create a figure and a set of subplots\n",
    "fig, axs = plt.subplots(nrows=len(unique_models), ncols=len(settings), figsize=(12, 4 * len(unique_models)), sharey=True)\n",
    "\n",
    "# Handle the case where there is only one model to prevent indexing error on axs\n",
    "if len(unique_models) == 1:\n",
    "    axs = axs.reshape(1, 2)\n",
    "\n",
    "# Iterate through models (rows) and settings (columns)\n",
    "for i, model in enumerate(unique_models):\n",
    "    for j, setting in enumerate(settings):\n",
    "        ax = axs[i, j]\n",
    "\n",
    "        # Filter data for the current subplot\n",
    "        df_plot_filtered = df_filtered[(df_filtered['dataset'] == model) & (df_filtered['setting'] == setting)].copy()\n",
    "\n",
    "        # Normalize 'count_in_role_gen' within this subplot\n",
    "        max_val = df_plot_filtered['count_in_role_gen'].max()\n",
    "        if max_val > 0:\n",
    "            df_plot_filtered['normalized_count'] = df_plot_filtered['count_in_role_gen'] / max_val\n",
    "        else:\n",
    "            df_plot_filtered['normalized_count'] = 0\n",
    "\n",
    "        # Plot for each pattern group using the normalized values\n",
    "        for pattern_group in df_plot_filtered['pattern_group'].unique():\n",
    "            df_pattern = df_plot_filtered[df_plot_filtered['pattern_group'] == pattern_group]\n",
    "            linestyle = '--' if pattern_group == 0 else '-'\n",
    "            label = f'Pattern Group {pattern_group}'\n",
    "            color = colors[setting]\n",
    "\n",
    "            ax.plot(df_pattern['turn'], df_pattern['normalized_count'],\n",
    "                    linestyle=linestyle, color=color, label=label)\n",
    "\n",
    "        # Set labels and title\n",
    "        ax.set_title(f'Model: {model}\\nSetting: {setting}')\n",
    "        ax.set_xlabel('Turn')\n",
    "        ax.set_ylabel('Normalized Count in Role Gen')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "        ax.set_ylim(0, 1.1)\n",
    "\n",
    "# Adjust layout and save the figure\n",
    "plt.tight_layout()\n",
    "#plt.savefig('normalized_model_performance_subplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deff793-2cb8-4049-9d79-28efb3cae701",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_filtered = master_df.groupby([\"role\", \"turn\", \"setting\", \"pattern_group\"]).agg({\"count_in_role_gen\": \"sum\", \"count_in_no_role_gen\": \"sum\"}).reset_index().copy()\n",
    "\n",
    "# Get unique, reordered models from the filtered data\n",
    "unique_models = np.unique(df_filtered.role)\n",
    "\n",
    "# Define unique settings\n",
    "settings = df_filtered['setting'].unique()\n",
    "\n",
    "# Define colors for settings\n",
    "colors = {'goal-oriented': 'blue', 'persona-directed': 'orange'}\n",
    "\n",
    "# Create a figure and a set of subplots\n",
    "fig, axs = plt.subplots(nrows=len(unique_models), ncols=len(settings), figsize=(12, 4 * len(unique_models)), sharey=True)\n",
    "\n",
    "# Handle the case where there is only one model to prevent indexing error on axs\n",
    "if len(unique_models) == 1:\n",
    "    axs = axs.reshape(1, 2)\n",
    "\n",
    "# Iterate through models (rows) and settings (columns)\n",
    "for i, model in enumerate(unique_models):\n",
    "    for j, setting in enumerate(settings):\n",
    "        ax = axs[i, j]\n",
    "\n",
    "        # Filter data for the current subplot\n",
    "        df_plot_filtered = df_filtered[(df_filtered['role'] == model) & (df_filtered['setting'] == setting)].copy()\n",
    "\n",
    "        # Normalize 'count_in_role_gen' within this subplot\n",
    "        max_val = df_plot_filtered['count_in_role_gen'].max()\n",
    "        if max_val > 0:\n",
    "            df_plot_filtered['normalized_count'] = df_plot_filtered['count_in_role_gen'] / max_val\n",
    "        else:\n",
    "            df_plot_filtered['normalized_count'] = 0\n",
    "\n",
    "        # Plot for each pattern group using the normalized values\n",
    "        for pattern_group in df_plot_filtered['pattern_group'].unique():\n",
    "            df_pattern = df_plot_filtered[df_plot_filtered['pattern_group'] == pattern_group]\n",
    "            linestyle = '--' if pattern_group == 0 else '-'\n",
    "            label = f'Pattern Group {pattern_group}'\n",
    "            color = colors[setting]\n",
    "\n",
    "            ax.plot(df_pattern['turn'], df_pattern['normalized_count'],\n",
    "                    linestyle=linestyle, color=color, label=label)\n",
    "\n",
    "        # Set labels and title\n",
    "        ax.set_title(f'Model: {model}\\nSetting: {setting}')\n",
    "        ax.set_xlabel('Turn')\n",
    "        ax.set_ylabel('Normalized Count in Role Gen')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "        ax.set_ylim(0, 1.1)\n",
    "\n",
    "# Adjust layout and save the figure\n",
    "plt.tight_layout()\n",
    "#plt.savefig('normalized_model_performance_subplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199cdced-549f-43cf-8e2c-fd83ad1c12c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = master_df.copy()\n",
    "\n",
    "# Aggregate data by setting, turn, and pattern_group, averaging across all models\n",
    "df_aggregated = df.groupby(['setting', 'turn', 'pattern_group'], as_index=False).agg(\n",
    "    avg_count_in_role_gen=('count_in_role_gen', 'mean')\n",
    ")\n",
    "\n",
    "# Define unique settings and colors\n",
    "settings = df_aggregated['setting'].unique()\n",
    "colors = {'goal-oriented': 'blue', 'persona-directed': 'orange'}\n",
    "\n",
    "# Create a figure with a 1x2 grid of subplots\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(8, 6), sharex=True)\n",
    "\n",
    "# Iterate through each setting and plot the data\n",
    "for j, setting in enumerate([\"persona-directed\", \"goal-oriented\"]):\n",
    "    ax = axs[j]\n",
    "\n",
    "    # Filter data for the current subplot\n",
    "    df_plot = df_aggregated[df_aggregated['setting'] == setting].copy()\n",
    "\n",
    "    # Normalize 'avg_count_in_role_gen' within this subplot\n",
    "    max_val = df_plot['avg_count_in_role_gen'].max()\n",
    "    if max_val > 0:\n",
    "        df_plot['normalized_count'] = df_plot['avg_count_in_role_gen'] / max_val\n",
    "    else:\n",
    "        df_plot['normalized_count'] = 0\n",
    "\n",
    "    # Plot for each pattern group using the normalized values\n",
    "    for pattern_group in df_plot['pattern_group'].unique():\n",
    "        df_pattern = df_plot[df_plot['pattern_group'] == pattern_group]\n",
    "        linestyle = '--' if pattern_group == 0 else '-'\n",
    "        label = \"Persona patterns\" if pattern_group==1 else \"Baseline patterns\"\n",
    "        color = colors[setting]\n",
    "\n",
    "        ax.plot(df_pattern['turn'], df_pattern['normalized_count'],\n",
    "                linestyle=linestyle, color=color, label=label)\n",
    "\n",
    "    # Set labels and title\n",
    "    ax.set_title(f'Pattern counts in {setting} dialogues', fontproperties=bold_font, fontsize=14)\n",
    "    ax.set_xlabel('Turn')\n",
    "    ax.set_ylabel('')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    ax.set_ylim(0, 1.1)\n",
    "fig.text(0.007, 0.5, 'Normalized Pattern Count', va='center', rotation='vertical')\n",
    "\n",
    "# Adjust layout and save the figure\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e757624-5435-4b13-a9cb-57a1e8b6bca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('../persistent-personas-paper/media/pypremise.pdf', dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1825a8-4c6a-4360-8e3e-db451bccd588",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd49c0a-52e5-450b-b20b-b105046a6319",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = master_df.groupby([\"model\", \"turn\", \"role\", \"setting\", \"pattern_group\"]).agg({\"count_in_role_gen\": \"sum\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bca274b-ba06-48bd-b6e5-66a9cb3c6566",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"modelRole\"] = df[\"model\"] + df[\"role\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbb6c17-f043-47a9-a8fb-d4f0a29e8b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "persona_df = df[df.setting == \"persona-directed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430f172a-74ae-4e65-b081-1b7722e623cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_df = df[df.setting == \"goal-oriented\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e935c0e-c993-4a61-ac49-b3693a62dc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "persona_df.groupby(\"turn\").sum(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7378a083-1564-49a7-a090-aab9eb367cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for all_df in [persona_df, goal_df]:\n",
    "    for pattern_group in [0, 1]:\n",
    "        print(f\"Regression for pattern group {pattern_group} and {all_df.setting.tolist()[0]}\")\n",
    "        df = all_df[all_df.pattern_group==pattern_group]\n",
    "        md = smf.mixedlm(f\"count_in_role_gen ~ turn\", df, groups=df[\"modelRole\"]) \n",
    "        mdf = md.fit(method=[\"powell\", \"lbfgs\"])\n",
    "        coefs = mdf.summary().tables[1]\n",
    "        coefs[\"Coef.\"] = coefs[\"Coef.\"].astype(\"float\")\n",
    "        display(coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009c7f57-90e6-4e3a-b334-7b495db320f4",
   "metadata": {},
   "source": [
    "### Difference between last and first rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86683db1-c011-4b29-8d1f-78c0ee56bdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "roles = [x for x in json.load(open(\"./data/roles.json\", \"r\")).keys()][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4627e5a2-6f43-45ef-b60b-aca78757d2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = [\"\", \"inst-\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf313598-19c2-445d-88d3-680896de4d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = []\n",
    "role_list = []\n",
    "count_first_list = []\n",
    "count_last_list = []\n",
    "dataset_list = []\n",
    "dialogue_type_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e8364f-87ae-48e8-aafb-8c781be6363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in model_order:\n",
    "    for dataset in DATASETS:\n",
    "        for prefix in prefixes:\n",
    "            for role in roles:\n",
    "                count_first_list.append((len(pd.read_csv(f\"./results/premise/premise_{model}_{dataset}_{role.replace(\" \", \"_\")}.csv\"))))\n",
    "                count_last_list.append((len(pd.read_csv(f\"./results/premise/premise_{model}_{prefix}{dataset}_{role.replace(\" \", \"_\")}_last_round.csv\"))))\n",
    "                model_list.append(model)\n",
    "                role_list.append(role)\n",
    "                dataset_list.append(dataset)\n",
    "                dialogue_type_list.append(\"Persona-directed\" if prefix == \"\" else \"Goal-oriented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99e069f-d049-4c71-a4c3-cfac95705b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"model\": model_list, \"dataset\": dataset_list, \"role\": role_list, \"dialogue_type\": dialogue_type_list, \"count_first\": count_first_list, \"count_last\": count_last_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ef55b9-dfa5-45e9-bb6f-4151383a40d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(\"count_last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a85fd27-85ee-435c-bf7c-0e9d19a14384",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_map = {\n",
    "        \"Llama-3.1-Nemotron-Nano-8B-v1\": \"Nemotron-8B\",\n",
    "        \"Llama-3_3-Nemotron-Super-49B-v1\": \"Nemotron-49B\",\n",
    "        \"gemma-3-4b-it\": \"Gemma3-4B\",\n",
    "        \"gemma-3-27b-it\": \"Gemma3-27B\",\n",
    "        \"Qwen3-4B-Instruct-2507\": \"Qwen3-4B\",\n",
    "        \"Qwen3-30B-A3B-Instruct-2507\": \"Qwen3-30B\",\n",
    "        \"gemini-2.5-flash\": \"gemini-2.5-flash\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ad384a-7618-435d-98c1-735b94aba817",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.model = df.model.apply(lambda x: model_name_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7e06f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "1-(df[\"count_last\"]/df[\"count_first\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ffbc11-a3a7-49b7-9de5-da3bb5a188f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted = df.melt(\n",
    "    id_vars=[\"model\", \"dataset\", \"role\", \"dialogue_type\"],\n",
    "    value_vars=[\"count_first\", \"count_last\"],\n",
    "    var_name=\"Position\",\n",
    "    value_name=\"Count\"\n",
    ")\n",
    "df_melted[\"Position\"] = df_melted[\"Position\"].map({\n",
    "    \"count_first\": \"First round\", \"count_last\": \"Last round\"\n",
    "})\n",
    "\n",
    "# Plot grouped bar chart\n",
    "g = sns.catplot(\n",
    "    sharey=False,\n",
    "    data=df_melted,\n",
    "    kind=\"bar\",\n",
    "    x=\"model\",\n",
    "    y=\"Count\",\n",
    "    hue=\"Position\",\n",
    "    col=\"dialogue_type\",\n",
    "    row=\"dataset\",\n",
    "    order=list(model_name_map.values()),\n",
    "    height=4, aspect=2,\n",
    ")\n",
    "\n",
    "# Add dashed vertical lines (your code is fine)\n",
    "for ax_row in g.axes:\n",
    "    for ax in ax_row:\n",
    "        for boundary in [2, 4, 6]:\n",
    "            ax.axvline(boundary - 0.5, color=\"gray\", linestyle=\"--\")\n",
    "\n",
    "g.tick_params(axis='x', labelrotation=45)\n",
    "\n",
    "# Get handles and labels from any subplot\n",
    "handles, labels = g.axes[0, 0].get_legend_handles_labels()\n",
    "\n",
    "# Create your new, desired legend for the entire figure\n",
    "# g.fig.legend(\n",
    "#     handles=handles,\n",
    "#     labels=labels,\n",
    "#     loc='upper center',\n",
    "#     bbox_to_anchor=(0.5, 1.03),\n",
    "#     ncol=2,\n",
    "#     title=None\n",
    "# )\n",
    "\n",
    "sns.move_legend(\n",
    "    g, \"upper center\",\n",
    "    bbox_to_anchor=(.45, 1.03), ncol=2, title=None, frameon=True,\n",
    ")\n",
    "# Adjust layout to make room for the new legend and labels\n",
    "#plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4c46e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[\"count_last\"] / df[\"count_first\"]).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01ec119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_difference(data, num_bootstraps=10000, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Performs bootstrapping to find the confidence interval for the difference of means.\n",
    "\n",
    "    Args:\n",
    "        data1 (pd.Series or np.array): The first dataset.\n",
    "        data2 (pd.Series or np.array): The second dataset.\n",
    "        num_bootstraps (int): The number of bootstrap iterations.\n",
    "        alpha (float): The significance level for the confidence interval.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the lower and upper bounds of the confidence interval,\n",
    "               and a message about the statistical significance.\n",
    "    \"\"\"\n",
    "    frac_means = []\n",
    "    n = len(data)\n",
    "\n",
    "    for _ in range(num_bootstraps):\n",
    "        # Create bootstrap samples by sampling with replacement.\n",
    "        sample = data.sample(n, replace=True)\n",
    "\n",
    "\n",
    "        # Calculate the difference in means and store it.\n",
    "        frac =  (sample[\"count_last\"] / sample[\"count_first\"]).mean()\n",
    "        frac_means.append(frac)\n",
    "\n",
    "    # Calculate the confidence interval from the list of fracerences.\n",
    "    lower_ci = np.percentile(frac_means, 100 * (alpha / 2))\n",
    "    upper_ci = np.percentile(frac_means, 100 * (1 - alpha / 2))\n",
    "\n",
    "    # Interpret the results.\n",
    "    if upper_ci < 1:\n",
    "        conclusion = \"The difference is statistically significant. count_first is significantly larger than count_last.\"\n",
    "    elif lower_ci > 1:\n",
    "        conclusion = \"The difference is statistically significant. count_last is significantly larger than count_first.\"\n",
    "    else:\n",
    "        conclusion = \"The difference is not statistically significant. The confidence interval includes one.\"\n",
    "\n",
    "    return lower_ci, upper_ci, conclusion\n",
    "\n",
    "# Run the analysis on the 'count_first' and 'count_last' columns.\n",
    "ci_lower, ci_upper, result_message = bootstrap_difference(df)\n",
    "\n",
    "# Print the results in a human-readable format.\n",
    "print(\"--- Bootstrapping Analysis ---\")\n",
    "print(f\"95% Confidence Interval for (count_last / count_first): [{ci_lower:.2f}, {ci_upper:.2f}]\")\n",
    "print(result_message)\n",
    "print(f\"\\nMean of 'count_last'/'count_first': {(df['count_last']/df['count_first']).mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6d90f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[\"count_last\"]/df[\"count_first\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2544994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - ci_lower, 1-ci_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ce4425-c0a2-46ad-9344-889680d6c13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_difference(data, num_bootstraps=10000, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Performs bootstrapping to find the confidence interval for the difference of means.\n",
    "\n",
    "    Args:\n",
    "        data1 (pd.Series or np.array): The first dataset.\n",
    "        data2 (pd.Series or np.array): The second dataset.\n",
    "        num_bootstraps (int): The number of bootstrap iterations.\n",
    "        alpha (float): The significance level for the confidence interval.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the lower and upper bounds of the confidence interval,\n",
    "               and a message about the statistical significance.\n",
    "    \"\"\"\n",
    "    diff_means = []\n",
    "    n = len(data)\n",
    "\n",
    "    for _ in range(num_bootstraps):\n",
    "        # Create bootstrap samples by sampling with replacement.\n",
    "        sample = data.sample(n, replace=True)\n",
    "\n",
    "\n",
    "        # Calculate the difference in means and store it.\n",
    "        diff = (sample[\"count_first\"] - sample[\"count_last\"]).mean()\n",
    "        diff_means.append(diff)\n",
    "\n",
    "    # Calculate the confidence interval from the list of differences.\n",
    "    lower_ci = np.percentile(diff_means, 100 * (alpha / 2))\n",
    "    upper_ci = np.percentile(diff_means, 100 * (1 - alpha / 2))\n",
    "\n",
    "    # Interpret the results.\n",
    "    if lower_ci > 0:\n",
    "        conclusion = \"The difference is statistically significant. count_first is significantly larger than count_last.\"\n",
    "    elif upper_ci < 0:\n",
    "        conclusion = \"The difference is statistically significant. count_last is significantly larger than count_first.\"\n",
    "    else:\n",
    "        conclusion = \"The difference is not statistically significant. The confidence interval includes zero.\"\n",
    "\n",
    "    return lower_ci, upper_ci, conclusion\n",
    "\n",
    "# Run the analysis on the 'count_first' and 'count_last' columns.\n",
    "ci_lower, ci_upper, result_message = bootstrap_difference(df)\n",
    "\n",
    "# Print the results in a human-readable format.\n",
    "print(\"--- Bootstrapping Analysis ---\")\n",
    "print(f\"95% Confidence Interval for (count_first - count_last): [{ci_lower:.2f}, {ci_upper:.2f}]\")\n",
    "print(result_message)\n",
    "print(f\"\\nMean of 'count_first': {df['count_first'].mean():.2f}\")\n",
    "print(f\"Mean of 'count_last': {df['count_last'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e39211-4d7d-4f65-b411-a2dc91226dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_oriented_df= df[df['dialogue_type'] == 'Goal-oriented']\n",
    "persona_directed_df = df[df['dialogue_type'] == 'Persona-directed']\n",
    "# Run the analysis on the 'count_first' and 'count_last' columns.\n",
    "\n",
    "\n",
    "ci_lower, ci_upper, result_message = bootstrap_difference(persona_directed_df)\n",
    "\n",
    "# Print the results in a human-readable format.\n",
    "print(\"--- Bootstrapping Analysis ---\")\n",
    "print(f\"95% Confidence Interval for (count_first - count_last): [{ci_lower:.2f}, {ci_upper:.2f}]\")\n",
    "print(result_message)\n",
    "print(f\"\\nMean of 'count_first': {persona_directed_df['count_first'].mean():.2f}\")\n",
    "print(f\"Mean of 'count_last': {persona_directed_df['count_last'].mean():.2f}\")\n",
    "\n",
    "ci_lower, ci_upper, result_message = bootstrap_difference(goal_oriented_df)\n",
    "\n",
    "# Print the results in a human-readable format.\n",
    "print(\"--- Bootstrapping Analysis ---\")\n",
    "print(f\"95% Confidence Interval for (count_first - count_last): [{ci_lower:.2f}, {ci_upper:.2f}]\")\n",
    "print(result_message)\n",
    "print(f\"\\nMean of 'count_first': {goal_oriented_df['count_first'].mean():.2f}\")\n",
    "print(f\"Mean of 'count_last': {goal_oriented_df['count_last'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd5a163-4010-4ba0-8a1b-fb42beb8d08a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "persistent-personas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
