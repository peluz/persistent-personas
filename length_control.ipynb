{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341f5cf0-5c65-44fd-8317-c72cda946c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import glob\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80788c40-342b-45e5-8c05-f31ba95aeb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auto_tokenizer(model_name: str):\n",
    "  \"\"\"\n",
    "  Returns the appropriate tokenizer from Hugging Face for a given model.\n",
    "\n",
    "  Args:\n",
    "      model_name (str): The name of the model.\n",
    "\n",
    "  Returns:\n",
    "      AutoTokenizer: The initialized tokenizer object.\n",
    "  \"\"\"\n",
    "  model_to_tokenizer = {\n",
    "      'Llama-3.1-Nemotron-Nano-8B-v1': 'nvidia/Llama-3.1-Nemotron-Nano-8B-v1',\n",
    "      'Llama-3_3-Nemotron-Super-49B-v1': 'nvidia/Llama-3_3-Nemotron-Super-49B-v1',\n",
    "      'Qwen3-30B-A3B-Instruct-2507': 'Qwen/Qwen3-30B-A3B-Instruct-2507',\n",
    "      'Qwen3-4B-Instruct-2507': 'Qwen/Qwen3-4B-Instruct-2507',\n",
    "      'gemma-3-27b-it': 'google/gemma-3-27b-it',\n",
    "      'gemma-3-4b-it': 'google/gemma-3-4b-it',\n",
    "      'gemini-2.5-flash': 'google/gemma-3-27b-it',\n",
    "  }\n",
    "  \n",
    "  # The Gemini models are not publicly available on Hugging Face.\n",
    "  if model_name in model_to_tokenizer:\n",
    "    tokenizer_name = model_to_tokenizer[model_name]\n",
    "    return AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "  else:\n",
    "    raise ValueError(f\"Model name '{model_name}' not supported. Please choose from: {list(model_to_tokenizer.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e74fbd-034f-4158-b399-812d894266aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = np.unique([x.split(\"/\")[2] for x in interviews])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189da3df-79ed-4105-a913-3cd5dba5c020",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokenizers = {model: get_auto_tokenizer(model) for model in models}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf2a393-a5ac-4825-a420-68ac31b68638",
   "metadata": {},
   "outputs": [],
   "source": [
    "interviews =  glob.glob(\"./generations/*/interview*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2cf474-fe3b-4edd-ba30-b23f041a14e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "idxs = []\n",
    "counts = []\n",
    "roles =  []\n",
    "for interview in tqdm(interviews):\n",
    "    tokenizer = all_tokenizers[interview.split(\"/\")[2]]\n",
    "    if \"shuffle\" in interview: continue\n",
    "    dialogue = json.load(open(interview, \"r\"))\n",
    "    parts = interview.split(\"/\")\n",
    "    model = parts[2]\n",
    "    role = parts[3].replace(\"_shuffle\", \"\").split(\"_\", maxsplit=1)[-1].replace(\".json\", \"\").replace(\"_\", \" \")\n",
    "    old_count = 0\n",
    "    idxs.append(0)\n",
    "    counts.append(0)\n",
    "    models.append(model)\n",
    "    roles.append(role)\n",
    "    for i in range(0, len(dialogue)//2):\n",
    "        new_count = len(tokenizer.apply_chat_template(dialogue[i*2:i*2+2], tokenize=True))\n",
    "        if i != 0: new_count -= 1 #remove bos token\n",
    "        old_count += new_count\n",
    "        models.append(model)\n",
    "        idxs.append(i+1)\n",
    "        counts.append(old_count)\n",
    "        roles.append(role)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce2eb93-1066-40d1-908b-cc68a09f202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "persona_df = pd.DataFrame({\"model\": models, \"role\": roles, \"pos\": idxs, \"n_tokens\": counts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e287605f-9429-4f9a-a3d3-f1f51f1cda62",
   "metadata": {},
   "outputs": [],
   "source": [
    "interviews =  glob.glob(\"./generations/*/instructions_*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ca10d7-5af3-4052-b83c-f221b2906332",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "idxs = []\n",
    "counts = []\n",
    "roles =  []\n",
    "for interview in tqdm(interviews):\n",
    "    tokenizer = all_tokenizers[interview.split(\"/\")[2]]\n",
    "    if \"shuffle\" in interview: continue\n",
    "    dialogue = json.load(open(interview, \"r\"))\n",
    "    parts = interview.split(\"/\")\n",
    "    model = parts[2]\n",
    "    role = parts[3].replace(\"_shuffle\", \"\").split(\"_\", maxsplit=1)[-1].replace(\".json\", \"\").replace(\"_\", \" \")\n",
    "    old_count = 0\n",
    "    idxs.append(0)\n",
    "    counts.append(0)\n",
    "    models.append(model)\n",
    "    roles.append(role)\n",
    "    for i in range(0, len(dialogue)//2):\n",
    "        new_count = len(tokenizer.apply_chat_template(dialogue[i*2:i*2+2], tokenize=True))\n",
    "        if i != 0: new_count -= 1 #remove bos token\n",
    "        old_count += new_count\n",
    "        models.append(model)\n",
    "        idxs.append(i+1)\n",
    "        counts.append(old_count)\n",
    "        roles.append(role)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0bd9fa-a0f8-40ba-8c44-130493f5419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_df = pd.DataFrame({\"model\": models, \"role\": roles, \"pos\": idxs, \"n_tokens\": counts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df58a8c4-9bc8-44d9-b03c-6b90823404c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_df = pd.merge(persona_df, goal_df, on=[\"model\", \"role\", \"pos\"],suffixes=[\"_persona_directed\", \"_goal_oriented\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0460d4f5-818e-49d9-a8ac-a73b7bad982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_df[length_df.pos==102].groupby(['model', 'pos'])[['n_tokens_persona_directed', 'n_tokens_goal_oriented']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5b9fdd-4f57-4769-aee2-bbe30d75c3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = length_df.copy()\n",
    "df_model_avg = df.groupby(['model', 'pos'])[['n_tokens_persona_directed', 'n_tokens_goal_oriented']].mean().reset_index()\n",
    "\n",
    "# Plot counts over 'pos' for different 'models'\n",
    "plt.figure(figsize=(10, 6))\n",
    "for model in df_model_avg['model'].unique():\n",
    "    subset = df_model_avg[df_model_avg['model'] == model]\n",
    "    plt.plot(subset['pos'], subset['n_tokens_persona_directed'], marker=\"o\", label=model)\n",
    "    plt.plot(subset['pos'], subset['n_tokens_goal_oriented'], marker=\"x\", label=model)\n",
    "plt.title('Average Token Count by Position for Different Models')\n",
    "plt.xlabel('Position')\n",
    "plt.ylabel('Average Token Count')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2557a07c-510f-4f68-97ad-6c77f7ffd418",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_df[length_df.pos==102].groupby(['role', 'pos'])[['n_tokens_persona_directed', 'n_tokens_goal_oriented']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd769ab-4b1f-430d-b77e-0fffbf1dcbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Group by 'role' and 'pos' and calculate the mean of 'n_tokens'\n",
    "df_role_avg = df.groupby(['role', 'pos'])[['n_tokens_persona_directed', 'n_tokens_goal_oriented']].mean().reset_index()\n",
    "\n",
    "# Plot counts over 'pos' for different 'roles'\n",
    "plt.figure(figsize=(10, 6))\n",
    "for role in df_role_avg['role'].unique():\n",
    "    subset = df_role_avg[df_role_avg['role'] == role]\n",
    "    plt.plot(subset['pos'], subset['n_tokens_persona_directed'], marker=\"o\", label=role)\n",
    "    plt.plot(subset['pos'], subset['n_tokens_goal_oriented'], marker=\"x\", label=role)\n",
    "plt.title('Average Token Count by Position for Different Roles')\n",
    "plt.xlabel('Position')\n",
    "plt.ylabel('Average Token Count')\n",
    "plt.legend(title='Role')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b5bf0b-76af-4b40-9a77-176ab074af1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_df.to_csv(\"./results/round_lengths.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04962a89-5ca3-41ab-8b3f-801a6ec6f778",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "persistent-personas",
   "language": "python",
   "name": "persistent-personas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
